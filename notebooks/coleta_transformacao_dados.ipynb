{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendador de artigos - Open Alex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_dataframe_por_termos(df, termos):\n",
    "    \n",
    "    termos_formatados = [f\"`{termo}`\" if ' ' in termo else termo for termo in termos]\n",
    "    \n",
    "    filtro = \" or \".join(f\"{termo} > 0\" for termo in termos_formatados)\n",
    "    \n",
    "    df_filtrado = df.query(filtro).loc[:, ['doi', 'title','abstract', 'publication_date', 'open_access'] + termos]\n",
    "    \n",
    "    return df_filtrado\n",
    "\n",
    "def filtrar_dataframe_por_acesso_aberto(df,resposta):\n",
    "    \n",
    "    if resposta == 'Sim':\n",
    "        df = df.query('open_access == True')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def criar_coluna_score(df):\n",
    "    \n",
    "    df['score'] = df.iloc[:,4:].sum(axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def atribuir_fator_termo_score(df, termos):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    df_copy['title'] = df_copy['title'].fillna('')\n",
    "    \n",
    "    for term in termos:\n",
    "        mask = df_copy['title'].str.upper().str.contains(term.upper())\n",
    "        df_copy.loc[mask, 'score'] *= 2\n",
    "        \n",
    "        mask = df_copy['abstract'].str.upper().str.contains(term.upper())\n",
    "        df_copy.loc[mask, 'score'] *= 1.5\n",
    "    \n",
    "    df_copy = df_copy.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def atribuir_fator_termo_similar_score(df, termos_similares):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    df_copy['title'] = df_copy['title'].fillna('')\n",
    "    \n",
    "    for term in termos_similares:\n",
    "        mask = df_copy['title'].str.upper().str.contains(term.upper())\n",
    "        df_copy.loc[mask, 'score'] *= 1.5\n",
    "        \n",
    "        mask = df_copy['abstract'].str.upper().str.contains(term.upper())\n",
    "        df_copy.loc[mask, 'score'] *= 1.25\n",
    "    \n",
    "    df_copy = df_copy.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def normalizar_score(df):\n",
    "    min_score = df['score'].min()\n",
    "    max_score = df['score'].max()\n",
    "\n",
    "\n",
    "    df['score_normalizado'] = ((df['score'] - min_score) / (max_score - min_score))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/processed/df_concatenado.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59437 entries, 0 to 59436\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   doi                    59437 non-null  object \n",
      " 1   title                  59437 non-null  object \n",
      " 2   abstract               59437 non-null  object \n",
      " 3   publication_date       59437 non-null  object \n",
      " 4   open_access            59437 non-null  bool   \n",
      " 5   concepts               59437 non-null  object \n",
      " 6   Computer science       59437 non-null  float64\n",
      " 7   Mathematics            59437 non-null  float64\n",
      " 8   Physics                59437 non-null  float64\n",
      " 9   Biology                59437 non-null  float64\n",
      " 10  Chemistry              59437 non-null  float64\n",
      " 11  Political science      59437 non-null  float64\n",
      " 12  Engineering            59437 non-null  float64\n",
      " 13  Materials science      59437 non-null  float64\n",
      " 14  Philosophy             59437 non-null  float64\n",
      " 15  Business               59437 non-null  float64\n",
      " 16  Psychology             59437 non-null  float64\n",
      " 17  Art                    59437 non-null  float64\n",
      " 18  Medicine               59437 non-null  float64\n",
      " 19  Geography              59437 non-null  float64\n",
      " 20  Geology                59437 non-null  float64\n",
      " 21  Economics              59437 non-null  float64\n",
      " 22  Sociology              59437 non-null  float64\n",
      " 23  Environmental science  59437 non-null  float64\n",
      " 24  History                59437 non-null  float64\n",
      "dtypes: bool(1), float64(19), object(5)\n",
      "memory usage: 10.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10851"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('abstract == \"\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18256304995205008"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('abstract == \"\"').shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concepts</th>\n",
       "      <th>nao_nulos</th>\n",
       "      <th>percentual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Medicine</td>\n",
       "      <td>19176</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computer science</td>\n",
       "      <td>17706</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biology</td>\n",
       "      <td>11332</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Physics</td>\n",
       "      <td>8156</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chemistry</td>\n",
       "      <td>8315</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Psychology</td>\n",
       "      <td>8282</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>7170</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Materials science</td>\n",
       "      <td>6878</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>7093</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Political science</td>\n",
       "      <td>6382</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>4153</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Geography</td>\n",
       "      <td>4060</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business</td>\n",
       "      <td>4325</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Geology</td>\n",
       "      <td>2737</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Economics</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Philosophy</td>\n",
       "      <td>3213</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Environmental science</td>\n",
       "      <td>2996</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Art</td>\n",
       "      <td>2613</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>History</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 concepts  nao_nulos  percentual\n",
       "12               Medicine      19176        0.32\n",
       "0        Computer science      17706        0.30\n",
       "3                 Biology      11332        0.19\n",
       "2                 Physics       8156        0.14\n",
       "4               Chemistry       8315        0.14\n",
       "10             Psychology       8282        0.14\n",
       "6             Engineering       7170        0.12\n",
       "7       Materials science       6878        0.12\n",
       "1             Mathematics       7093        0.12\n",
       "5       Political science       6382        0.11\n",
       "16              Sociology       4153        0.07\n",
       "13              Geography       4060        0.07\n",
       "9                Business       4325        0.07\n",
       "14                Geology       2737        0.05\n",
       "15              Economics       3001        0.05\n",
       "8              Philosophy       3213        0.05\n",
       "17  Environmental science       2996        0.05\n",
       "11                    Art       2613        0.04\n",
       "18                History       1172        0.02"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts = []\n",
    "qtd_de_valores_nao_nulos = []\n",
    "pct_valores_nao_nulos = []\n",
    "\n",
    "for i,j in df.iloc[:,6:].items():\n",
    "    concepts.append(i)\n",
    "    qtd_de_valores_nao_nulos.append(df.shape[0] - sum(j==0))\n",
    "    pct_valores_nao_nulos.append(round(((df.shape[0] - sum(j==0))/ df.shape[0]),2))\n",
    "    \n",
    "    \n",
    "pd.DataFrame({'concepts':concepts,\n",
    "              'nao_nulos':qtd_de_valores_nao_nulos,\n",
    "              'percentual':pct_valores_nao_nulos}).sort_values(by='percentual',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doi\n",
      "title\n",
      "abstract\n",
      "publication_date\n",
      "open_access\n",
      "concepts\n",
      "Computer science\n",
      "Mathematics\n",
      "Physics\n",
      "Biology\n",
      "Chemistry\n",
      "Political science\n",
      "Engineering\n",
      "Materials science\n",
      "Philosophy\n",
      "Business\n",
      "Psychology\n",
      "Art\n",
      "Medicine\n",
      "Geography\n",
      "Geology\n",
      "Economics\n",
      "Sociology\n",
      "Environmental science\n",
      "History\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = filtrar_dataframe_por_termos(df,['Economics'])\n",
    "\n",
    "df_filtrado = filtrar_dataframe_por_acesso_aberto(df_filtrado,'Não')\n",
    "\n",
    "df_filtrado = criar_coluna_score(df_filtrado)\n",
    "\n",
    "df_filtrado = atribuir_fator_termo_score(df_filtrado,['Econometria'])\n",
    "\n",
    "df_filtrado = atribuir_fator_termo_similar_score(df_filtrado,\n",
    "                                                 ['Econometrics', 'Regression analysis', \n",
    "                                                  'Time series analysis', 'Statistical modeling',\n",
    "                                                  'Hypothesis testing','Econometria', 'Análise de regressão',\n",
    "                                                  'Análise de séries temporais', 'Modelagem estatística',\n",
    "                                                  'Teste de hipótese'])\n",
    "\n",
    "df_filtrado = normalizar_score(df_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_escolha(areas,acesso_aberto,termo,termo_similar):\n",
    "    \n",
    "    df_filtrado = filtrar_dataframe_por_termos(df,areas)\n",
    "\n",
    "    df_filtrado = filtrar_dataframe_por_acesso_aberto(df_filtrado,acesso_aberto)\n",
    "\n",
    "    df_filtrado = criar_coluna_score(df_filtrado)\n",
    "\n",
    "    df_filtrado = atribuir_fator_termo_score(df_filtrado,termo)\n",
    "\n",
    "    df_filtrado = atribuir_fator_termo_similar_score(df_filtrado,termo_similar)\n",
    "\n",
    "    df_filtrado = normalizar_score(df_filtrado)\n",
    "\n",
    "    return df_filtrado.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TÍTULO': Fiscal space and government-spending cyclicality: Disparity between the procyclical and the countercyclical\n",
      "'RESUMO': Abstract This study employs quantile regression analysis on a dataset encompassing 160 countries spanning the period from 1990 to 2020. Its primary objective is study investigate analysis relationship between fiscal space and various conditional quantiles of government-spending cyclicality. Unlike prior literature, which predominantly centers on government debt sustainability, our on introduces a comprehensive perspective to encompassing space, the dimensions that have received comparatively limited attention. These the include sovereign balance sheet vulnerability, contingent liabilities arising the risks associated with external the private sector debt, the market perceptions the the risk. Our the suggests dimensions from to is statistically significant only at fiscal upper part fiscal space and and cyclicality distribution, i.e., fiscally procyclical countries. We also find that, in and and countries, conditional share of foreign currency sovereign of total of procyclical fiscally in of of share held by nonresidents of of government-spending government-spending total government-spending cyclicality. short-term government government government in that share government ratio total debt debt debt tax revenue, natural resource dependence, debt inflation rate are debt debt higher debt procyclicality. In contrast, factors such as in sovereign rating, financial depth, associated associated with with external external debt, external debt, debt, in share total lower short-term are JEC codes: H30, H60, H63\n",
      "'DATA DE PUBLICAÇÃO': 2023-10-06\n",
      "'DOI': https://doi.org/10.21203/rs.3.rs-3376767/v1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'TÍTULO': CONTRIBUTION OF INDONESIAN NATIONAL STANDARD (SNI) ON GROSS DOMESTIC PRODUCTS (GDP)\n",
      "'RESUMO': &lt;p&gt;Gross Domestic Product (GDP) is the number of goods and services produced by a country in is certain period as is measuring tool for a country's economic development. GDP comprises many factors, including national household consumption, investment, state is exports, the imports. Standards are inherent consumption, the a the produced, consumed, the nationally the internationally traded. This study aims to determine a effect number standards on GDP. The method used of econometrics through case studies of Indonesia of considering of independent goods namely fixed capital, and and workers, patents, and Indonesian National Standard (SNI), while and dependent factor and and and results showed that services 1% percent increase by SNI, by a a in labor could in Indonesia's in in 0.3%, 0.08%, 0.04%, increase 0.4 %, with alpha 5% from 1998 in 2017, respectively. With an average SNI growth in 5.43%, GDP contribution GDP factors, to 1.63% year to SNI patents, to growth. In monetary terms, GDP. The fixed capital, total 1% average 2017 increased increase about 5.9 trillion SNI GDP.&lt;/p&gt;&lt;div&gt; &lt;/div&gt;\n",
      "'DATA DE PUBLICAÇÃO': 2023-10-04\n",
      "'DOI': https://doi.org/10.31153/js.v25i2.992\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'TÍTULO': The Effect of Per Capita Income and the Agricultural Sector on Goods and Services Tax Receipts with Economic Growth as Moderation in BRICS Countries\n",
      "'RESUMO': The purpose of this research is to analyze the effect The per capita income and The agricultural sector on goods The services tax revenues with economic growth as The moderation in of combined economy countries, BRICS (Brazil, Russia, India, China, of South Africa). and variables used the of study are of ratio of this research research is revenue, is is income, to contribution to in to sector, the to percentage the the growth. the data source comes from the World Bank Data for and period 2010 the 2018. the the method the the quantitative using panel the effect multiple linear regression analysis techniques. effect Random Effect Model goods a model selected based tax services per testing. Simultaneously, all per have model significant per capita capita and capita and revenues. Partially, data a and and panel economic and and used and and negative have significant agricultural agricultural agricultural on on This on revenues. expected goods provide insight goods goods governments a services services countries services making policies tax optimize tax tax revenues economic economic through growth in BRICS variables income, income, sector, sector, growth.\n",
      "'DATA DE PUBLICAÇÃO': 2023-10-03\n",
      "'DOI': https://doi.org/10.31092/jpkn.v5i1.2315\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'TÍTULO': AN ANALYTICAL STUDY OF PUBLIC HEALTH EXPENDITURE AND ECONOMIC GROWTH IN EASTERN STATES OF INDIA\n",
      "'RESUMO': This study examines a comparative analysis of the trend and pattern This healthcare expenditure in four major eastern states This India. The study is completely built on secondary sources study data from 1991 to 2020 taken of study RBI Database, a World Bank Database a various governmental reports. from of has used descriptive statistics, Log-linear regression, least square of of graphical methods for analysis. of of shows of percentage share of total health of the GSDP the an increasing trend. According the the regression analysis, the spending the the strong favourable effect the the the trend health and The and and A rise and and state GSDP expenditure helps has accomplish in maximum productive capacity in human capital in thereby increase four productivity eastern market structure. So, sound states plays India. significant role on sources economic growth to development has from nation. to paper makes health case that governments should take immediate steps to produce alternative income to different health including foreign grants an alternative tax revenue. KEY WORDS: Economic growth, Health- Expenditure, Regression, Time series\n",
      "'DATA DE PUBLICAÇÃO': 2023-10-05\n",
      "'DOI': https://doi.org/10.36713/epra14543\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'TÍTULO': Regression analysis of the efficiency of the use of production resources of a large-scale agroindustrial enterprise, depending on specialization and location\n",
      "'RESUMO': The author’s methodology of analysis has been developed, which makes it possible to calculate the efficiency The of use the production resources of all main types of agricultural production, depending on of regional location. of distribution of large-scale agroindustrial enterprises by specialization of of revealed. Selected factors that have has greatest impact been the effectiveness the activities. A factorial a nalysis the t he efficiency depending on on large-scale enterprise a agroindustrial specialization and location was carried out.\n",
      "'DATA DE PUBLICAÇÃO': 2023-10-03\n",
      "'DOI': https://doi.org/10.29235/1818-9806-2023-9-3-22\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_filtrado_top = df_filtrado.head(5).reset_index(drop=True).loc[:,['doi','title','abstract','publication_date']]\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"'TÍTULO': {df_filtrado_top['title'].iloc[i]}\")\n",
    "    print(f\"'RESUMO': {df_filtrado_top['abstract'].iloc[i]}\")\n",
    "    print(f\"'DATA DE PUBLICAÇÃO': {df_filtrado_top['publication_date'].iloc[i]}\")\n",
    "    print(f\"'DOI': {df_filtrado_top['doi'].iloc[i]}\")    \n",
    "    print(100*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PROMPT:\n",
    "\n",
    "79 TOKENS - CUSTO: $ 0.00011850000000000001\n",
    "'''\n",
    "\n",
    "A partir desse termo ['econometrics']. \n",
    "Gere 5 termos relacionados (como um tesauro) em inglês e suas respectivas traduções em português. \n",
    "\n",
    "Responda com uma única lista Python.\n",
    "\n",
    "Como nesse exemplo: \n",
    "['\"Artificial Intelligence\",\"Inteligência Artificial\"]\n",
    "\n",
    "Não responda mais nada além da lista.\n",
    "\n",
    "'''\n",
    "    TOKENS: 68 TOKENS - CUSTO: $ 0.00013600000000000003\n",
    "    RESPOSTA\n",
    "        ['Quantitative Analysis', 'Análise Quantitativa', 'Statistical Modeling', 'Modelagem Estatística', 'Regression Analysis', 'Análise de Regressão', 'Time Series Analysis', 'Análise de Séries Temporais', 'Econometric Models', 'Modelos Econométricos']\n",
    "\n",
    "\n",
    "90 TOKENS - CUSTO: $ 0.000138\n",
    "'''\n",
    "A partir de cada termo ['econometrics','policy','taxa de câmbio']. \n",
    "Gere 5 termos relacionados (como um tesauro) em inglês e suas respectivas traduções em português. \n",
    "\n",
    "Responda com uma única lista Python todos os termos.\n",
    "\n",
    "Como nesse exemplo: \n",
    "['\"Artificial Intelligence\",\"Inteligência Artificial\"]\n",
    "\n",
    "Não responda mais nada além da lista.\n",
    "'''\n",
    "\n",
    "    TOKENS: 197 TOKENS - CUSTO: $ 0.00039400000000000004\n",
    "    RESPOSTA \n",
    "    ['econometrics', 'econometria', 'econometric analysis', 'análise econométrica', 'econometric models', 'modelos econométricos', 'econometric methods', 'métodos econométricos', 'economic modeling', 'modelagem econômica',\n",
    "    'policy', 'política', 'government policy', 'política governamental', 'public policy', 'política pública', 'foreign policy', 'política externa', 'economic policy', 'política econômica',\n",
    "    'taxa de câmbio', 'exchange rate', 'taxa de câmbio', 'currency exchange rate', 'taxa de câmbio de moeda', 'foreign exchange rate', 'taxa de câmbio estrangeira', 'exchange rate fluctuations', 'flutuações na taxa de câmbio', 'exchange rate system', 'sistema de taxa de câmbio']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOKENS INPUT:\n",
    "\n",
    "    80 A 120 \n",
    "\n",
    "    Custo = 0.00012 a 0.00018\n",
    "\n",
    "TOKENS OUTPUT:\n",
    "\n",
    "    70 a 220\n",
    "\n",
    "    Custo = 0.00014 a 0.00044\n",
    "\n",
    "Custo total = 0.00026 a 0.00062\n",
    "Custo por 1.000: 0.26 a 0.62\n",
    "Custo por 10.000: 2.6 a 6.2\n",
    "Custo por 100.000: 26 a 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00062"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.00018 + 0.00044"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOKENS INPUT:\n",
    "\n",
    "    1450 A 2500\n",
    "\n",
    "    Custo = 0.0022 a 0.004\n",
    "\n",
    "TOKENS OUTPUT:\n",
    "\n",
    "    190 a 300\n",
    "\n",
    "    Custo = 0.00038 a 0.0006\n",
    "\n",
    "Custo total = 0.0026 a 0.0046\n",
    "Custo por 1.000: 2.6 a 4.6\n",
    "Custo por 10.000: 26 a 46\n",
    "Custo por 100.000: 260 a 460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0046"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.004 + 0.0006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUSTO TOTAL\n",
    "\n",
    "Custo total = 0.00286 a 0.00522\n",
    "Custo por 1.000: 2.86 a 5.22\n",
    "Custo por 10.000: 28.6 a 52.2\n",
    "Custo por 100.000: 286 a 522\n",
    "\n",
    "\n",
    "Dólar = $ 5.0\n",
    "\n",
    "Custo por 1.000: 1.43 a 2.61\n",
    "Custo por 10.000: 143 a 261\n",
    "Custo por 100.000: 1430 a 2610\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1240"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "62*5*4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.00286 a 0.00522 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2610"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "522 * 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(300/1000)*\t0.002 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2500/1000)*\t0.0015 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def chave_open_ai():\n",
    "    \n",
    "    with open('../../../credentials_open_ai.json','r') as json_file:\n",
    "        dados = json.load(json_file)\n",
    "        api_key = dados.get('OPEN_AI_API_KEY')\n",
    "        \n",
    "        \n",
    "    return api_key    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = chave_open_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Econometria']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termo = ['Econometria']\n",
    "termo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "artigos = '''\n",
    "    ### [Artificial Intelligence and Wastewater Treatment: A Global Scientific Perspective through Text Mining](https://doi.org/10.3390/w15193487)\n",
    "\n",
    "    **Data de Publicação**: 2023-10-05\n",
    "\n",
    "    **Resumo**: The concept of using wastewater as a substitute for limited water resources and environmental protection has enabled this sector to make major technological advancements and, The The result, of given us an abundance of physical data, including chemical, biological, of microbiological information. It is easier of comprehend of treatment systems after studying of data. In order of achieve this, of number of studies use machine learning (ML) algorithms of has proactive approach of solving issues wastewater modeling the functionalities wastewater these processing wastewater while utilizing wastewater experimental data gathered. wastewater goal as a article as the as textual analysis techniques a extract a most popular to a models from scientific documents in for “Web and Science” database limited analyze their relevance and historical development. This will help provide and general overview and global and follow-up and publications dealing with this application to artificial intelligence (AI) and overcome the challenges faced and systems and technologies. this findings suggest that developed countries are this use publishers to articles on to research topic, to the to scientific major publication trend reveals an exponential rise an numbers, reflecting learning machine community’s interest is is subject. As well, is results indicate treatment supervised treatment treatment data. among researchers, machine machine Artificial Neural Network (ANN), Random Forest (RF), Support Vector Machine (SVM), Linear Regression (LR), Adaptive Neuro-Fuzzy Inference System (ANFIS), Decision Tree (DT), in Gradient Boosting (GB) being machine learning learning learning learning frequently employed algorithms the the the domain. Research the optimization methods the the the the well-known method the calibrating that the genetic the (GA). Finally, the the benefits data analysis by enhancing analysis most accuracy most efficiency. Yet popular arise models model training demands ample, high-quality models Moreover, models scientific interpretability in in in in complicates comprehension with challenges underlying mechanisms that decisions on reveals treatment.\n",
    "\n",
    "    ### [Application of Computer-aided Artificial Intelligence Techniques in Food Industry](https://doi.org/10.9734/cjast/2023/v42i344230)\n",
    "\n",
    "    **Data de Publicação**: 2023-10-05\n",
    "\n",
    "    **Resumo**: The incorporation of Computer-aided artificial intelligence (AI) into the food business has signaled The beginning The a new age of innovation and transformation. This review paper digs of the different applications of of artificial in intelligence into industry. AI is altering operations, increasing efficiency into transforming customer experiences the industries ranging from agriculture to the processing, manufacturing, supply chain management, delivery services the restaurants. the report delves the how the food being used for precision farming, quality monitoring, food food optimization, individualized consumer interactions business other applications. While highlighting in advantages, a analysis also addresses problems such as financial constraints, and scarcity and experienced specialists and regional differences and adoption. It emphasizes and symbiotic relationship between and in human knowledge, emphasizing that AI supplements AI functions rather than replacing them. AI chain finishes by supply AI's potential human move is efficiency to toward greater sustainability, report consumer emphasizing happiness.\n",
    "\n",
    "    ### [The benefits and costs of explainable artificial intelligence in visual\n",
    "    quality control: Evidence from fault detection performance and eye movements](https://doi.org/10.48550/arxiv.2310.01220)\n",
    "\n",
    "    **Data de Publicação**: 2023-10-02\n",
    "\n",
    "    **Resumo**: Visual inspection tasks often require humans to cooperate with AI-based image classifiers. To enhance this cooperation, explainable artificial intelligence (XAI) can highlight those to areas that have contributed to an AI decision. However, the literature on visual cueing suggests with such XAI support might come image costs of its own. To better understand how this benefits and cost can that depend that that accuracy that that classifications that an highlights, we conducted two experiments of simulated AI quality control in a chocolate factory. Participants had and decide whether AI moulds contained faulty bars or not, However, were always informed the the of chocolate classified the mould as XAI the not. In half the the experiment, they saw additional whether highlights the justified the classification. While the speeded up performance, or effects the error rates faulty highly dependent on (X)AI accuracy. had XAI the observed when the system correctly detected on highlighted on fault, but visual XAI XAI evident for misplaced XAI XAI marked XAI intact area while costs actual fault was located elsewhere. Eye movement analyses indicated and participants spent less time searching of rest of its its benefits thus looked at and were and often. we were also were large interindividual differences. Taken together, mould results suggest highlights despite less potentials, observed fault discourage people from investing effort into their own information analysis.\n",
    "\n",
    "    ### [Artificial Intelligence Powered Writing Tools as Adaptable Aids for Academic Writing: Insight from EFL College Learners in Writing Final Project](https://doi.org/10.47191/ijmra/v6-i10-15)\n",
    "\n",
    "    **Data de Publicação**: 2023-10-05\n",
    "\n",
    "    **Resumo**: This research investigates the viewpoint of English as a Foreign Language (EFL) students about using Artificial Intelligence (AI) This writing aids for their culminating project. the study utilized the convenience sampling method to recruit 50 8th-semester the from public and private colleges in North Sumatra, Indonesia, who were completing the final assignments. Data was collected the open-ended questionnaires the interview approaches, while data analysis the performed the SPSS version 29.0. The results indicate that the favor as utilization viewpoint of of of was composition of of of assignment. Despite of scarcity a of Intelligence, it does not diminish as favorable perspective on and necessity a employing students students students using their aid. Students' positive perception using utilizing Artificial Artificial Artificial composing Artificial Artificial assignments influences Intelligence efficacy Intelligence caliber Intelligence Intelligence written work. Hence, writing writing their expressed by in regarding their their their their culminating underscores and numerous benefits these in tools offer in final completion final utilization favorable projects.\n",
    "\n",
    "    ### [Artificial Intelligence applied to Software Testing: a Tertiary Study](https://doi.org/10.1145/3616372)\n",
    "\n",
    "    **Data de Publicação**: 2023-10-06\n",
    "\n",
    "    **Resumo**: Context: Artificial intelligence (AI) methods and models have extensively been applied to support different phases of the software development lifecycle, including and testing (ST). Several secondary studies investigated and interplay between AI and ST but restricted software scope and and research and specific domains or sub-domains within either area. Objective: This and aims and explore and overall contribution and and the ST, while identifying to most popular applications to potential paths for future to directions. Method: We executed a tertiary study following well-established guidelines research conducting systematic literature mappings in to engineering to to answering nine to questions. Results : the identified support analyzed 20 relevant of studies. The analysis was performed by drawing from well-recognized the of of taxonomies for mapping the selected the according the them. AI resulting the software discussions provide extensive testing detailed information on secondary mapping for studies interplay ST. Conclusion: We application between research AI The AI is AI well-consolidated ST growing interest ST topic. research research for for our future can be used a researchers study identify opportunities in The research, The by practitioners looking by evidence-based from mapping which AI-supported technology resulting possibly adopt information their on processes.\n",
    "\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chama_api_gera_paragrafo(artigos):\n",
    "    \n",
    "    resposta = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Você é uma bibliotecária, especialista em linguagem documentária (tesauros).\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f'''\n",
    "                        Sou uma biblioteca que gostaria de recomendar novos papers para os usuários. \n",
    "\n",
    "                        A partir desses papers publicados na última semana:\n",
    "\n",
    "                        [\n",
    "                        {artigos}\n",
    "                        ]\n",
    "\n",
    "                        Crie um parágrafo inicial de um e-mail resumindo o conteúdo geral de todos os papers, como uma newsletter científica fazendo publicidade.\n",
    "\n",
    "                        Dê continuidade a esse início:\n",
    "                        \n",
    "                        \"\"\"\n",
    "                        Nossa biblioteca está de volta para trazer as últimas descobertas e insights fresquinhos da pesquisa científica publicada na última semana. \n",
    "                        \"\"\"\n",
    "                        \n",
    "                        Escreva apenas um parágrafo.\n",
    "                         \n",
    "                        Seja conciso.\n",
    "                        \n",
    "                        '''\n",
    "                },\n",
    "                ],\n",
    "                temperature=1,\n",
    "                max_tokens=256,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=1,\n",
    "                stop=[]\n",
    "            )\n",
    "    \n",
    "        \n",
    "    return resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta = chama_api_gera_paragrafo(artigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragrafo = resposta.get('choices')[0].get('message').get('content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formata_paragrafo(paragrafo):\n",
    "    \n",
    "    texto = paragrafo.replace('. ','.\\n')\n",
    "\n",
    "    linhas = texto.splitlines()\n",
    "    linhas.insert(-1, '') #Adicionando espaço duplo na última linha\n",
    "\n",
    "    texto_formatado = '\\n'.join(linhas)\n",
    "    \n",
    "    return texto_formatado\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nossa biblioteca está de volta para trazer as últimas descobertas e insights fresquinhos da pesquisa científica publicada na última semana.\n",
      "Nesta edição, exploramos diversos temas, desde o uso de inteligência artificial no tratamento de águas residuais até a aplicação de técnicas de IA na indústria alimentícia.\n",
      "Também analisamos os benefícios e custos da inteligência artificial explicável no controle de qualidade visual e destacamos o potencial das ferramentas de escrita com inteligência artificial para auxiliar estudantes universitários na redação de projetos finais.\n",
      "Além disso, investigamos a aplicação da inteligência artificial nos testes de software e suas contribuições para o desenvolvimento dessa área.\n",
      "\n",
      "Continue lendo para ficar por dentro das últimas novidades científicas!\n"
     ]
    }
   ],
   "source": [
    "print(formata_paragrafo(paragrafo))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
