{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendador de artigos - Open Alex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_dataframe_por_termos(df, termos):\n",
    "    \n",
    "    termos_formatados = [f\"`{termo}`\" if ' ' in termo else termo for termo in termos]\n",
    "    \n",
    "    filtro = \" or \".join(f\"{termo} > 0\" for termo in termos_formatados)\n",
    "    \n",
    "    df_filtrado = df.query(filtro).loc[:, ['doi', 'title','abstract', 'publication_date', 'open_access'] + termos]\n",
    "    \n",
    "    return df_filtrado\n",
    "\n",
    "def filtrar_dataframe_por_acesso_aberto(df,resposta):\n",
    "    \n",
    "    if resposta == 'Sim':\n",
    "        df = df.query('open_access == True')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def criar_coluna_score(df):\n",
    "    \n",
    "    df['score'] = df.iloc[:,4:].sum(axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def atribuir_fator_termo_score(df, termos):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    df_copy['title'] = df_copy['title'].fillna('')\n",
    "    \n",
    "    for term in termos:\n",
    "        mask = df_copy['title'].str.upper().str.contains(term.upper())\n",
    "        df_copy.loc[mask, 'score'] *= 2\n",
    "        \n",
    "        mask = df_copy['abstract'].str.upper().str.contains(term.upper())\n",
    "        df_copy.loc[mask, 'score'] *= 1.5\n",
    "    \n",
    "    df_copy = df_copy.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def atribuir_fator_termo_similar_score(df, termos_similares):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    df_copy['title'] = df_copy['title'].fillna('')\n",
    "    \n",
    "    for term in termos_similares:\n",
    "        mask = df_copy['title'].str.upper().str.contains(term.upper())\n",
    "        df_copy.loc[mask, 'score'] *= 1.5\n",
    "        \n",
    "        mask = df_copy['abstract'].str.upper().str.contains(term.upper())\n",
    "        df_copy.loc[mask, 'score'] *= 1.25\n",
    "    \n",
    "    df_copy = df_copy.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def normalizar_score(df):\n",
    "    min_score = df['score'].min()\n",
    "    max_score = df['score'].max()\n",
    "\n",
    "\n",
    "    df['score_normalizado'] = ((df['score'] - min_score) / (max_score - min_score))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/processed/df_concatenado.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59437 entries, 0 to 59436\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   doi                    59437 non-null  object \n",
      " 1   title                  59437 non-null  object \n",
      " 2   abstract               59437 non-null  object \n",
      " 3   publication_date       59437 non-null  object \n",
      " 4   open_access            59437 non-null  bool   \n",
      " 5   concepts               59437 non-null  object \n",
      " 6   Computer science       59437 non-null  float64\n",
      " 7   Mathematics            59437 non-null  float64\n",
      " 8   Physics                59437 non-null  float64\n",
      " 9   Biology                59437 non-null  float64\n",
      " 10  Chemistry              59437 non-null  float64\n",
      " 11  Political science      59437 non-null  float64\n",
      " 12  Engineering            59437 non-null  float64\n",
      " 13  Materials science      59437 non-null  float64\n",
      " 14  Philosophy             59437 non-null  float64\n",
      " 15  Business               59437 non-null  float64\n",
      " 16  Psychology             59437 non-null  float64\n",
      " 17  Art                    59437 non-null  float64\n",
      " 18  Medicine               59437 non-null  float64\n",
      " 19  Geography              59437 non-null  float64\n",
      " 20  Geology                59437 non-null  float64\n",
      " 21  Economics              59437 non-null  float64\n",
      " 22  Sociology              59437 non-null  float64\n",
      " 23  Environmental science  59437 non-null  float64\n",
      " 24  History                59437 non-null  float64\n",
      "dtypes: bool(1), float64(19), object(5)\n",
      "memory usage: 10.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10851"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('abstract == \"\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18256304995205008"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('abstract == \"\"').shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concepts</th>\n",
       "      <th>nao_nulos</th>\n",
       "      <th>percentual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Medicine</td>\n",
       "      <td>19176</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computer science</td>\n",
       "      <td>17706</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biology</td>\n",
       "      <td>11332</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Physics</td>\n",
       "      <td>8156</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chemistry</td>\n",
       "      <td>8315</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Psychology</td>\n",
       "      <td>8282</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>7170</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Materials science</td>\n",
       "      <td>6878</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>7093</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Political science</td>\n",
       "      <td>6382</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>4153</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Geography</td>\n",
       "      <td>4060</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business</td>\n",
       "      <td>4325</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Geology</td>\n",
       "      <td>2737</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Economics</td>\n",
       "      <td>3001</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Philosophy</td>\n",
       "      <td>3213</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Environmental science</td>\n",
       "      <td>2996</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Art</td>\n",
       "      <td>2613</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>History</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 concepts  nao_nulos  percentual\n",
       "12               Medicine      19176        0.32\n",
       "0        Computer science      17706        0.30\n",
       "3                 Biology      11332        0.19\n",
       "2                 Physics       8156        0.14\n",
       "4               Chemistry       8315        0.14\n",
       "10             Psychology       8282        0.14\n",
       "6             Engineering       7170        0.12\n",
       "7       Materials science       6878        0.12\n",
       "1             Mathematics       7093        0.12\n",
       "5       Political science       6382        0.11\n",
       "16              Sociology       4153        0.07\n",
       "13              Geography       4060        0.07\n",
       "9                Business       4325        0.07\n",
       "14                Geology       2737        0.05\n",
       "15              Economics       3001        0.05\n",
       "8              Philosophy       3213        0.05\n",
       "17  Environmental science       2996        0.05\n",
       "11                    Art       2613        0.04\n",
       "18                History       1172        0.02"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts = []\n",
    "qtd_de_valores_nao_nulos = []\n",
    "pct_valores_nao_nulos = []\n",
    "\n",
    "for i,j in df.iloc[:,6:].items():\n",
    "    concepts.append(i)\n",
    "    qtd_de_valores_nao_nulos.append(df.shape[0] - sum(j==0))\n",
    "    pct_valores_nao_nulos.append(round(((df.shape[0] - sum(j==0))/ df.shape[0]),2))\n",
    "    \n",
    "    \n",
    "pd.DataFrame({'concepts':concepts,\n",
    "              'nao_nulos':qtd_de_valores_nao_nulos,\n",
    "              'percentual':pct_valores_nao_nulos}).sort_values(by='percentual',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doi\n",
      "title\n",
      "abstract\n",
      "publication_date\n",
      "open_access\n",
      "concepts\n",
      "Computer science\n",
      "Mathematics\n",
      "Physics\n",
      "Biology\n",
      "Chemistry\n",
      "Political science\n",
      "Engineering\n",
      "Materials science\n",
      "Philosophy\n",
      "Business\n",
      "Psychology\n",
      "Art\n",
      "Medicine\n",
      "Geography\n",
      "Geology\n",
      "Economics\n",
      "Sociology\n",
      "Environmental science\n",
      "History\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = filtrar_dataframe_por_termos(df,['Economics'])\n",
    "\n",
    "df_filtrado = filtrar_dataframe_por_acesso_aberto(df_filtrado,'Não')\n",
    "\n",
    "df_filtrado = criar_coluna_score(df_filtrado)\n",
    "\n",
    "df_filtrado = atribuir_fator_termo_score(df_filtrado,['Econometria'])\n",
    "\n",
    "df_filtrado = atribuir_fator_termo_similar_score(df_filtrado,\n",
    "                                                 ['Econometrics', 'Regression analysis', \n",
    "                                                  'Time series analysis', 'Statistical modeling',\n",
    "                                                  'Hypothesis testing','Econometria', 'Análise de regressão',\n",
    "                                                  'Análise de séries temporais', 'Modelagem estatística',\n",
    "                                                  'Teste de hipótese'])\n",
    "\n",
    "df_filtrado = normalizar_score(df_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_escolha(areas,acesso_aberto,termo,termo_similar):\n",
    "    \n",
    "    df_filtrado = filtrar_dataframe_por_termos(df,areas)\n",
    "\n",
    "    df_filtrado = filtrar_dataframe_por_acesso_aberto(df_filtrado,acesso_aberto)\n",
    "\n",
    "    df_filtrado = criar_coluna_score(df_filtrado)\n",
    "\n",
    "    df_filtrado = atribuir_fator_termo_score(df_filtrado,termo)\n",
    "\n",
    "    df_filtrado = atribuir_fator_termo_similar_score(df_filtrado,termo_similar)\n",
    "\n",
    "    df_filtrado = normalizar_score(df_filtrado)\n",
    "\n",
    "    return df_filtrado.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TÍTULO': Fiscal space and government-spending cyclicality: Disparity between the procyclical and the countercyclical\n",
      "'RESUMO': Abstract This study employs quantile regression analysis on a dataset encompassing 160 countries spanning the period from 1990 to 2020. Its primary objective is study investigate analysis relationship between fiscal space and various conditional quantiles of government-spending cyclicality. Unlike prior literature, which predominantly centers on government debt sustainability, our on introduces a comprehensive perspective to encompassing space, the dimensions that have received comparatively limited attention. These the include sovereign balance sheet vulnerability, contingent liabilities arising the risks associated with external the private sector debt, the market perceptions the the risk. Our the suggests dimensions from to is statistically significant only at fiscal upper part fiscal space and and cyclicality distribution, i.e., fiscally procyclical countries. We also find that, in and and countries, conditional share of foreign currency sovereign of total of procyclical fiscally in of of share held by nonresidents of of government-spending government-spending total government-spending cyclicality. short-term government government government in that share government ratio total debt debt debt tax revenue, natural resource dependence, debt inflation rate are debt debt higher debt procyclicality. In contrast, factors such as in sovereign rating, financial depth, associated associated with with external external debt, external debt, debt, in share total lower short-term are JEC codes: H30, H60, H63\n",
      "'DATA DE PUBLICAÇÃO': 2023-10-06\n",
      "'DOI': https://doi.org/10.21203/rs.3.rs-3376767/v1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'TÍTULO': CONTRIBUTION OF INDONESIAN NATIONAL STANDARD (SNI) ON GROSS DOMESTIC PRODUCTS (GDP)\n",
      "'RESUMO': &lt;p&gt;Gross Domestic Product (GDP) is the number of goods and services produced by a country in is certain period as is measuring tool for a country's economic development. GDP comprises many factors, including national household consumption, investment, state is exports, the imports. Standards are inherent consumption, the a the produced, consumed, the nationally the internationally traded. This study aims to determine a effect number standards on GDP. The method used of econometrics through case studies of Indonesia of considering of independent goods namely fixed capital, and and workers, patents, and Indonesian National Standard (SNI), while and dependent factor and and and results showed that services 1% percent increase by SNI, by a a in labor could in Indonesia's in in 0.3%, 0.08%, 0.04%, increase 0.4 %, with alpha 5% from 1998 in 2017, respectively. With an average SNI growth in 5.43%, GDP contribution GDP factors, to 1.63% year to SNI patents, to growth. In monetary terms, GDP. The fixed capital, total 1% average 2017 increased increase about 5.9 trillion SNI GDP.&lt;/p&gt;&lt;div&gt; &lt;/div&gt;\n",
      "'DATA DE PUBLICAÇÃO': 2023-10-04\n",
      "'DOI': https://doi.org/10.31153/js.v25i2.992\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'TÍTULO': The Effect of Per Capita Income and the Agricultural Sector on Goods and Services Tax Receipts with Economic Growth as Moderation in BRICS Countries\n",
      "'RESUMO': The purpose of this research is to analyze the effect The per capita income and The agricultural sector on goods The services tax revenues with economic growth as The moderation in of combined economy countries, BRICS (Brazil, Russia, India, China, of South Africa). and variables used the of study are of ratio of this research research is revenue, is is income, to contribution to in to sector, the to percentage the the growth. the data source comes from the World Bank Data for and period 2010 the 2018. the the method the the quantitative using panel the effect multiple linear regression analysis techniques. effect Random Effect Model goods a model selected based tax services per testing. Simultaneously, all per have model significant per capita capita and capita and revenues. Partially, data a and and panel economic and and used and and negative have significant agricultural agricultural agricultural on on This on revenues. expected goods provide insight goods goods governments a services services countries services making policies tax optimize tax tax revenues economic economic through growth in BRICS variables income, income, sector, sector, growth.\n",
      "'DATA DE PUBLICAÇÃO': 2023-10-03\n",
      "'DOI': https://doi.org/10.31092/jpkn.v5i1.2315\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'TÍTULO': AN ANALYTICAL STUDY OF PUBLIC HEALTH EXPENDITURE AND ECONOMIC GROWTH IN EASTERN STATES OF INDIA\n",
      "'RESUMO': This study examines a comparative analysis of the trend and pattern This healthcare expenditure in four major eastern states This India. The study is completely built on secondary sources study data from 1991 to 2020 taken of study RBI Database, a World Bank Database a various governmental reports. from of has used descriptive statistics, Log-linear regression, least square of of graphical methods for analysis. of of shows of percentage share of total health of the GSDP the an increasing trend. According the the regression analysis, the spending the the strong favourable effect the the the trend health and The and and A rise and and state GSDP expenditure helps has accomplish in maximum productive capacity in human capital in thereby increase four productivity eastern market structure. So, sound states plays India. significant role on sources economic growth to development has from nation. to paper makes health case that governments should take immediate steps to produce alternative income to different health including foreign grants an alternative tax revenue. KEY WORDS: Economic growth, Health- Expenditure, Regression, Time series\n",
      "'DATA DE PUBLICAÇÃO': 2023-10-05\n",
      "'DOI': https://doi.org/10.36713/epra14543\n",
      "----------------------------------------------------------------------------------------------------\n",
      "'TÍTULO': Regression analysis of the efficiency of the use of production resources of a large-scale agroindustrial enterprise, depending on specialization and location\n",
      "'RESUMO': The author’s methodology of analysis has been developed, which makes it possible to calculate the efficiency The of use the production resources of all main types of agricultural production, depending on of regional location. of distribution of large-scale agroindustrial enterprises by specialization of of revealed. Selected factors that have has greatest impact been the effectiveness the activities. A factorial a nalysis the t he efficiency depending on on large-scale enterprise a agroindustrial specialization and location was carried out.\n",
      "'DATA DE PUBLICAÇÃO': 2023-10-03\n",
      "'DOI': https://doi.org/10.29235/1818-9806-2023-9-3-22\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_filtrado_top = df_filtrado.head(5).reset_index(drop=True).loc[:,['doi','title','abstract','publication_date']]\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"'TÍTULO': {df_filtrado_top['title'].iloc[i]}\")\n",
    "    print(f\"'RESUMO': {df_filtrado_top['abstract'].iloc[i]}\")\n",
    "    print(f\"'DATA DE PUBLICAÇÃO': {df_filtrado_top['publication_date'].iloc[i]}\")\n",
    "    print(f\"'DOI': {df_filtrado_top['doi'].iloc[i]}\")    \n",
    "    print(100*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PROMPT:\n",
    "\n",
    "79 TOKENS - CUSTO: $ 0.00011850000000000001\n",
    "'''\n",
    "\n",
    "A partir desse termo ['econometrics']. \n",
    "Gere 5 termos relacionados (como um tesauro) em inglês e suas respectivas traduções em português. \n",
    "\n",
    "Responda com uma única lista Python.\n",
    "\n",
    "Como nesse exemplo: \n",
    "['\"Artificial Intelligence\",\"Inteligência Artificial\"]\n",
    "\n",
    "Não responda mais nada além da lista.\n",
    "\n",
    "'''\n",
    "    TOKENS: 68 TOKENS - CUSTO: $ 0.00013600000000000003\n",
    "    RESPOSTA\n",
    "        ['Quantitative Analysis', 'Análise Quantitativa', 'Statistical Modeling', 'Modelagem Estatística', 'Regression Analysis', 'Análise de Regressão', 'Time Series Analysis', 'Análise de Séries Temporais', 'Econometric Models', 'Modelos Econométricos']\n",
    "\n",
    "\n",
    "90 TOKENS - CUSTO: $ 0.000138\n",
    "'''\n",
    "A partir de cada termo ['econometrics','policy','taxa de câmbio']. \n",
    "Gere 5 termos relacionados (como um tesauro) em inglês e suas respectivas traduções em português. \n",
    "\n",
    "Responda com uma única lista Python todos os termos.\n",
    "\n",
    "Como nesse exemplo: \n",
    "['\"Artificial Intelligence\",\"Inteligência Artificial\"]\n",
    "\n",
    "Não responda mais nada além da lista.\n",
    "'''\n",
    "\n",
    "    TOKENS: 197 TOKENS - CUSTO: $ 0.00039400000000000004\n",
    "    RESPOSTA \n",
    "    ['econometrics', 'econometria', 'econometric analysis', 'análise econométrica', 'econometric models', 'modelos econométricos', 'econometric methods', 'métodos econométricos', 'economic modeling', 'modelagem econômica',\n",
    "    'policy', 'política', 'government policy', 'política governamental', 'public policy', 'política pública', 'foreign policy', 'política externa', 'economic policy', 'política econômica',\n",
    "    'taxa de câmbio', 'exchange rate', 'taxa de câmbio', 'currency exchange rate', 'taxa de câmbio de moeda', 'foreign exchange rate', 'taxa de câmbio estrangeira', 'exchange rate fluctuations', 'flutuações na taxa de câmbio', 'exchange rate system', 'sistema de taxa de câmbio']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOKENS INPUT:\n",
    "\n",
    "    80 A 120 \n",
    "\n",
    "    Custo = 0.00012 a 0.00018\n",
    "\n",
    "TOKENS OUTPUT:\n",
    "\n",
    "    70 a 220\n",
    "\n",
    "    Custo = 0.00014 a 0.00044\n",
    "\n",
    "Custo total = 0.00026 a 0.00062\n",
    "Custo por 1.000: 0.26 a 0.62\n",
    "Custo por 10.000: 2.6 a 6.2\n",
    "Custo por 100.000: 26 a 62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sou uma biblioteca que gostaria de recomendar novos papers para seus usuários. \n",
    "\n",
    "A partir desses papers publicados na última semana:\n",
    "\n",
    "[\n",
    "### [Fiscal space and government-spending cyclicality: Disparity between the procyclical and the countercyclical](https://doi.org/10.21203/rs.3.rs-3376767/v1)\n",
    "\n",
    "**Data de Publicação**: 2023-10-06\n",
    "\n",
    "**Resumo**: Abstract This study employs quantile regression analysis on a dataset encompassing 160 countries spanning the period from 1990 to 2020. Its primary objective is study investigate analysis relationship between fiscal space and various conditional quantiles of government-spending cyclicality. Unlike prior literature, which predominantly centers on government debt sustainability, our on introduces a comprehensive perspective to encompassing space, the dimensions that have received comparatively limited attention. These the include sovereign balance sheet vulnerability, contingent liabilities arising the risks associated with external the private sector debt, the market perceptions the the risk. Our the suggests dimensions from to is statistically significant only at fiscal upper part fiscal space and and cyclicality distribution, i.e., fiscally procyclical countries. We also find that, in and and countries, conditional share of foreign currency sovereign of total of procyclical fiscally in of of share held by nonresidents of of government-spending government-spending total government-spending cyclicality. short-term government government government in that share government ratio total debt debt debt tax revenue, natural resource dependence, debt inflation rate are debt debt higher debt procyclicality. In contrast, factors such as in sovereign rating, financial depth, associated associated with with external external debt, external debt, debt, in share total lower short-term are JEC codes: H30, H60, H63\n",
    "\n",
    "### [The Effect of Per Capita Income and the Agricultural Sector on Goods and Services Tax Receipts with Economic Growth as Moderation in BRICS Countries](https://doi.org/10.31092/jpkn.v5i1.2315)\n",
    "\n",
    "**Data de Publicação**: 2023-10-03\n",
    "\n",
    "**Resumo**: The purpose of this research is to analyze the effect The per capita income and The agricultural sector on goods The services tax revenues with economic growth as The moderation in of combined economy countries, BRICS (Brazil, Russia, India, China, of South Africa). and variables used the of study are of ratio of this research research is revenue, is is income, to contribution to in to sector, the to percentage the the growth. the data source comes from the World Bank Data for and period 2010 the 2018. the the method the the quantitative using panel the effect multiple linear regression analysis techniques. effect Random Effect Model goods a model selected based tax services per testing. Simultaneously, all per have model significant per capita capita and capita and revenues. Partially, data a and and panel economic and and used and and negative have significant agricultural agricultural agricultural on on This on revenues. expected goods provide insight goods goods governments a services services countries services making policies tax optimize tax tax revenues economic economic through growth in BRICS variables income, income, sector, sector, growth.\n",
    "\n",
    "### [AN ANALYTICAL STUDY OF PUBLIC HEALTH EXPENDITURE AND ECONOMIC GROWTH IN EASTERN STATES OF INDIA](https://doi.org/10.36713/epra14543)\n",
    "\n",
    "**Data de Publicação**: 2023-10-05\n",
    "\n",
    "**Resumo**: This study examines a comparative analysis of the trend and pattern This healthcare expenditure in four major eastern states This India. The study is completely built on secondary sources study data from 1991 to 2020 taken of study RBI Database, a World Bank Database a various governmental reports. from of has used descriptive statistics, Log-linear regression, least square of of graphical methods for analysis. of of shows of percentage share of total health of the GSDP the an increasing trend. According the the regression analysis, the spending the the strong favourable effect the the the trend health and The and and A rise and and state GSDP expenditure helps has accomplish in maximum productive capacity in human capital in thereby increase four productivity eastern market structure. So, sound states plays India. significant role on sources economic growth to development has from nation. to paper makes health case that governments should take immediate steps to produce alternative income to different health including foreign grants an alternative tax revenue. KEY WORDS: Economic growth, Health- Expenditure, Regression, Time series\n",
    "\n",
    "### [Regression analysis of the efficiency of the use of production resources of a large-scale agroindustrial enterprise, depending on specialization and location](https://doi.org/10.29235/1818-9806-2023-9-3-22)\n",
    "\n",
    "**Data de Publicação**: 2023-10-03\n",
    "\n",
    "**Resumo**: The author’s methodology of analysis has been developed, which makes it possible to calculate the efficiency The of use the production resources of all main types of agricultural production, depending on of regional location. of distribution of large-scale agroindustrial enterprises by specialization of of revealed. Selected factors that have has greatest impact been the effectiveness the activities. A factorial a nalysis the t he efficiency depending on on large-scale enterprise a agroindustrial specialization and location was carried out.\n",
    "\n",
    "### [The Influence of Original Local Government Revenue, Specific Allocation Fund on Government Capital Expenditures in Southeast Sulawesi Disrict/ City](https://doi.org/10.33395/owner.v7i4.1937)\n",
    "\n",
    "**Data de Publicação**: 2023-10-02\n",
    "\n",
    "**Resumo**: This study aims to examine how the influence of Local Own Revenue and Special Allocation Funds on District/City Government Capital Expenditures in Southeast Sulawesi Province. The type study data used study this study is secondary data. study source study to the the in the The comes from Realization Reports the used this Expenditure Budget, data the the the the the influence of 2015-2021 of 17 Regencies/Cities of in from of Analysis of testing of of of Local Own Revenue panel and regression analysis using Eviews 10 software. and results Special Special Capital found that Special Regional Original Income variable has a significant effect on Allocation Allocation Allocation Funds with Funds in level this 0.0000, significant a variable Fund is on on data Province. Sulawesi Southeast in effect significant on a data with has 0.0000. As well as level variable Capital Capital Capital significant Capital this a Simultaneously or jointly have in The The variable this Expenditure is Expenditure Expenditure that that that Regional 0.00000. Original limitations variable Income effect are variable there significant still many factors are a with Expenditures, therefore it level hoped a further researchers can add other variables significant make them more varied.\n",
    "\n",
    "]\n",
    "\n",
    "Crie um parágrafo inicial de um e-mail resumindo o conteúdo geral de todos os papers, como uma newsletter científica fazendo publicidade.\n",
    "\n",
    "\n",
    "Dê continuidade a esse início:\n",
    "\n",
    "'''\n",
    "Olá,\n",
    "\n",
    "Nossa biblioteca está de volta para trazer as últimas descobertas e insights fresquinhos da pesquisa científica publicada na última semana. \n",
    "\n",
    "'''\n",
    "\n",
    "Seja conciso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "'''\n",
    "Olá,\n",
    "\n",
    "Nossa biblioteca está de volta para trazer as últimas descobertas e insights fresquinhos da pesquisa científica publicada na última semana. Nossos destaques incluem estudos que exploram a relação entre espaço fiscal e ciclicidade nos gastos governamentais, o impacto da renda per capita e do setor agrícola nas receitas de impostos sobre bens e serviços em países do BRICS, análises sobre os gastos com saúde e crescimento econômico nos estados do leste da Índia, a eficiência na utilização de recursos de produção em empresas agroindustriais em grande escala e o efeito da receita governamental local nas despesas de capital do governo no sudeste de Sulawesi. Essas pesquisas oferecem uma visão abrangente de questões econômicas e financeiras atuais, fornecendo valiosos insights para formuladores de políticas e acadêmicos.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sou uma biblioteca que gostaria de recomendar novos papers para seus usuários. \n",
    "\n",
    "A partir desses papers publicados na última semana:\n",
    "\n",
    "[\n",
    "\n",
    "]\n",
    "\n",
    "Crie um parágrafo inicial de um e-mail resumindo o conteúdo geral de todos os papers, como uma newsletter científica fazendo publicidade.\n",
    "\n",
    "\n",
    "Dê continuidade a esse início:\n",
    "\n",
    "'''\n",
    "Olá,\n",
    "\n",
    "Nossa biblioteca está de volta para trazer as últimas descobertas e insights fresquinhos da pesquisa científica publicada na última semana. \n",
    "\n",
    "'''\n",
    "\n",
    "Seja conciso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOKENS INPUT:\n",
    "\n",
    "    1450 A 2500\n",
    "\n",
    "    Custo = 0.0022 a 0.004\n",
    "\n",
    "TOKENS OUTPUT:\n",
    "\n",
    "    190 a 300\n",
    "\n",
    "    Custo = 0.00038 a 0.0006\n",
    "\n",
    "Custo total = 0.0026 a 0.0046\n",
    "Custo por 1.000: 2.6 a 4.6\n",
    "Custo por 10.000: 26 a 46\n",
    "Custo por 100.000: 260 a 460"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUSTO TOTAL\n",
    "\n",
    "Custo total = 0.00286 a 0.00522\n",
    "Custo por 1.000: 2.86 a 5.22\n",
    "Custo por 10.000: 28.6 a 52.2\n",
    "Custo por 100.000: 286 a 522\n",
    "\n",
    "\n",
    "Dólar = $ 5.0\n",
    "\n",
    "Custo por 1.000: 1.43 a 2.61\n",
    "Custo por 10.000: 143 a 261\n",
    "Custo por 100.000: 1430 a 2610\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2610"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "522 * 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(300/1000)*\t0.002 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00375"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2500/1000)*\t0.0015 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def chave_open_ai():\n",
    "    \n",
    "    with open('../../../credentials_open_ai.json','r') as json_file:\n",
    "        dados = json.load(json_file)\n",
    "        api_key = dados.get('OPEN_AI_API_KEY')\n",
    "        \n",
    "        \n",
    "    return api_key    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = chave_open_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Econometria']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termo = ['Econometria']\n",
    "termo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chama_api_gera_termos(termo):\n",
    "    \n",
    "    resposta = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Você é uma bibliotecária, especialista em linguagem documentária (tesauros).\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"A partir desses termos {termo}. \\nGere 5 termos relacionados (como um tesauro) para cada um deles, em inglês e suas respectivas traduções em português, mas retorne todos em conjunto.\\n\\nResponda com uma única lista Python todos os termos.\\n\\nComo nesse exemplo: \\n['Artificial Intelligence,'Inteligência Artificial']\\n\\nNão responda mais nada além da lista.\"\n",
    "\n",
    "                },\n",
    "                ],\n",
    "                temperature=1.05,\n",
    "                max_tokens=256,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "                stop=[\"30\"]\n",
    "            )\n",
    "    return resposta\n",
    "\n",
    "def gera_termos_relacionados(termo):\n",
    "    tentativas = 0\n",
    "\n",
    "    while tentativas < 3:\n",
    "        tentativas += 1\n",
    "\n",
    "        try:\n",
    "            resposta = chama_api_gera_termos(termo)\n",
    "            \n",
    "            termos_relacionados = resposta.get('choices')[0].get('message').get('content')\n",
    "            lista_termos_relacionados = eval(termos_relacionados)\n",
    "            \n",
    "            return lista_termos_relacionados\n",
    "\n",
    "        except TimeoutError:\n",
    "            print(\"Tempo limite excedido. Tentando novamente...\")\n",
    "            continue \n",
    "        \n",
    "        except SyntaxError:\n",
    "            print(\"Erro de sintaxe. Tentando novamente...\")\n",
    "            continue \n",
    "        \n",
    "        except openai.error.APIError as error:\n",
    "            print(f'Erro de API. {error}')\n",
    "\n",
    "    print(\"Número máximo de tentativas alcançado. Não foi possível obter uma resposta.\")\n",
    "    return None\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AJUSTAR TEMPO DE TENTATIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb Cell 35\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m api \u001b[39m=\u001b[39m chama_api_gera_termos([\u001b[39m'\u001b[39;49m\u001b[39mfilosofia\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m>\u001b[39m \u001b[39m20\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mErro\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb Cell 35\u001b[0m line \u001b[0;36mchama_api_gera_termos\u001b[0;34m(termo)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchama_api_gera_termos\u001b[39m(termo):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     resposta \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                 model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                 messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                 {\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mVocê é uma bibliotecária, especialista em linguagem documentária (tesauros).\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                 },\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                 {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mA partir desses termos \u001b[39;49m\u001b[39m{\u001b[39;49;00mtermo\u001b[39m}\u001b[39;49;00m\u001b[39m. \u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mGere 5 termos relacionados (como um tesauro) para cada um deles, em inglês e suas respectivas traduções em português, mas retorne todos em conjunto.\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39mResponda com uma única lista Python todos os termos.\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39mComo nesse exemplo: \u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m[\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mArtificial Intelligence,\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mInteligência Artificial\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39mNão responda mais nada além da lista.\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                 },\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                 ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                 temperature\u001b[39m=\u001b[39;49m\u001b[39m1.05\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                 max_tokens\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                 top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                 frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                 presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                 stop\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39m30\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m             )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/franciscofoz/Documents/GitHub/recomendador-artigos-OpenAlex-GPT/notebooks/coleta_transformacao_dados.ipynb#X56sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m resposta\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:220\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[1;32m    223\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    224\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    225\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    226\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    227\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[1;32m    230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:520\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    518\u001b[0m     _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n\u001b[1;32m    519\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    521\u001b[0m         method,\n\u001b[1;32m    522\u001b[0m         abs_url,\n\u001b[1;32m    523\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    524\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    525\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    526\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    527\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    528\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    530\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    531\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:699\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    698\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    700\u001b[0m     conn,\n\u001b[1;32m    701\u001b[0m     method,\n\u001b[1;32m    702\u001b[0m     url,\n\u001b[1;32m    703\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    704\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    705\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    706\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    707\u001b[0m )\n\u001b[1;32m    709\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    713\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:445\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    440\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    441\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    442\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    443\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    446\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    447\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:440\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    441\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    442\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    443\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "api = chama_api_gera_termos(['filosofia'])\n",
    "\n",
    "if time.time() - start_time > 20:\n",
    "    print('Erro')\n",
    "    \n",
    "\n",
    "THREADING e Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = gera_termos_relacionados(['fiolosofia','religião','espírito'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['philosophy',\n",
       " 'religion',\n",
       " 'spirit',\n",
       " 'metaphysics',\n",
       " 'ethics',\n",
       " 'ontology',\n",
       " 'epistemology',\n",
       " 'theology',\n",
       " 'spirituality',\n",
       " 'soul',\n",
       " 'filosofia',\n",
       " 'religião',\n",
       " 'espírito',\n",
       " 'metafísica',\n",
       " 'ética',\n",
       " 'ontologia',\n",
       " 'epistemologia',\n",
       " 'teologia',\n",
       " 'espiritualidade',\n",
       " 'alma']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
